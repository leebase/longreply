---
layout: page
title: "AI LeapFrog"
permalink: /longreply/AI_LeapFrog/
---
# AI Leap Frog

The models are all improving at a rapid pace. Everyone vies to be the smartest and bestest. It's really hard to judge them, but there are performace tests aplenty to compare them.  I go by my own personal use.

Here's some recent ones as I await the imminent release of ChatGPT 4.5.

## Claude 3.7 

Claude launched its latest and from all appearances is a much larger upgrade than the number (from 3.5) would suggest.  Claude was already at the top of  the charts for programming, but has gotten better.

My own testing - I can feel the update to the intelligence.  I have a model for time I call The Infinite Now (there is no past or future, only now).  Grok 3 Beta and Claude 3.7 are giving the best discussions.

There is a free tier but I believe you do need an account.

Claude claims they don't train on prompts but do statistically sample some prompts for human review for quality assurance.

Claude API is the most expensive by a good bit.
Claude subscription starts at $20/month.  I found that even with paying for Claude, I'd hit the limits on use of the most powerful model

## Grok 3 Beta

Elon claimed to have the smartest AI now, true or not, Grok 3 is definitely in the hunt.  Coming from nowhere to contending for the title in an amazingly small amount of time.

I only use the free tier from the X client.  It's great for asking questions about current events being talked about on X as it is continually updated without resorting to search.

Commercial tier is $40 as part of a Premium+ subscription to X or $30 for SuperGrok (no X).  While $30 is more than ChatGPT or Claude, it includes a Deep Research feature.  I will be testing it against the $200 ChatGPT Pro that I've been playing with for a month.  $30 might turn out to be a bargain.

Grok does not train on prompts.

## Deep Seek R1

The world was set ablaze at the claims this Chinese contender is just as smart as any other model and was trained for $5 million,.

Is it smart?  It is. It's in a class called a reasoning model.  It thinks through the solution and gives you visibility into its throught process.  

This model is quite capable, fast, and very inexpensive.  I wouldn't use it much, at least not the version hosted by the Chinese.  It has absolutely the worst data privacy policy.  But it's open source and other places are hosting.  You can even run a model locally.  Of course, at a "quantized" size, which reduces both the ram required but also the intelligence.

The open source models of DeepSeek won't train on your prompts.

## Gemini 2.0 Flash

Google was embarrassingly behind in the LLM race.  They should have been a front runner.  They responded quickly to ChatGPT, but Bard was such a poor model.  Gemini not much better.

Now with Gemini 2.0 Flash, they have a top tier model that's extremely fast and very inexpensive.  I'd put it at a notch or two lower than the best of the other models.  But - it's still very capable and with a price advantage.

I have only used the free tier and I have never hit a usage limit.  It has a 1M token limit which is HUGE.  I have had massive conversations without hitting that limit.  On the free tier.

I'd say Gemini 2.0 Flash has put Google back in the game.  Google has also come out with a coding agent, plug in to VS Code that I will explore.  It's free level is so generous, that the product will be effectively free for most people.  I have yet to try out Cursor or any of the other agents this is to compete with.  I just don't code enough to make paying for them worth while.  Looking forward to trying with Gemini.

Gemini does train on prompts

## ChatGPT 4o, o3-mini

The big dog of the field.  ChatGPT4o is still a top model, maybe the others are a little better at this or that.  But still holding up well and 4.5 is due any day now. 

The big news is the o3-mini models that are as smart as o1 (the full o1, not the mini), but run faster and are much cheaper.  These are thinking models. While DeepSeek R1 stole the show, introducing a thinking model - within weeks, the already announced o1 mini models were released.

I personally fall back to using 4o more than the o3-mini for my uses.  I really don't know why, but it is so.  I use these models all day long for different purposes.  I just keep going back to 4o. 

ChatGPT is also multi model.  It will generate images AND it will talk to you.  You can have full voice conversations.

There are other features, enough so that I pay the $20/mo for the ChatGPT Plus subscription. I liked Claude's 3.5 Sonnet model just a smidge better, but running into limits even though I was paying for it, and ChatGPT's other features, tipped the scale for me.

ChatGPT's free tier does not require signing up.
ChatGPT has a setting to opt out on training on prompts.

## T3 Chat

Going to throw in a plug for T3 Chat.  It gives you access to all of these models for a mere $8/mo.  For that you get 1500 messages and 100 premium (basically Claude as it's so expensive).  

It's a web app that is so fast you wonder why the native ChatGPT and Claude aren't faster.

It's my "Clauce for $8/mo" choice.  I actually use Gemini Flash for a lot of my T3 Chats as I don't want to blow threw my Claude credits and I have a separate ChatGPT subscription.  It's DeepSeek models are run from non-Chinese hosts.